{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('Data/_20230622-130921_training.tsv', sep='\\t', header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.rename(columns = {0: 'Value',\n",
    "                     1: 'Evidence_type',\n",
    "                     2: 'CCV'}, \n",
    "          inplace = True)\n",
    "\n",
    "# Remove evidence_type\n",
    "df.drop('Evidence_type', axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove ENG instances\n",
    "ENG_ccvs = [ccv for ccv in df['CCV'].unique() if 'ENG' in ccv]\n",
    "df = df[ ~df['CCV'].isin(ENG_ccvs) ]\n",
    "\n",
    "# Drop CCVs, which can be handled with hard-rules\n",
    "drop_CCVs = ['CCV:00004', 'CCV:00012', 'CCV:00013', 'CCV:00014', \n",
    "             'CCV:00071', 'CCV:00072', 'CCV:00073', 'CCV:00084', \n",
    "             'CCV:00094', 'CCV:00034', 'CCV:00035', 'CCV:00036', 'CCV:00100',\n",
    "             'CCV:00042', 'CCV:00043', 'CCV:00047', 'CCV:00048', \n",
    "             'CCV:00066', 'CCV:00067', 'CCV:00068', 'CCV:00069', \n",
    "             'CCV:00083', 'CCV:00028', 'CCV:00029', 'CCV:00079', \n",
    "             'CCV:00080', 'CCV:00081', 'CCV:00082', 'CCV:00085', \n",
    "             'CCV:00087', 'CCV:00088', 'CCV:00089', 'CCV:00090', \n",
    "             'CCV:00092', 'CCV:00093', 'CCV:00038', 'CCV:00022', \n",
    "             'CCV:00025', 'CCV:00026', 'CCV:00041', 'CCV:00053', \n",
    "             'CCV:00054', 'CCV:00049', 'CCV:00057', 'CCV:00058', \n",
    "             'CCV:00059', 'CCV:00061', 'CCV:00062', 'CCV:00063',\n",
    "             'CCV:00096', 'CCV:00097', 'CCV:00098', 'CCV:00099']\n",
    "\n",
    "df = df[ ~df['CCV'].isin(drop_CCVs) ]\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index().drop('index', axis=1)\n",
    "print('Number of records: ', df.shape[0])\n",
    "\n",
    "\n",
    "# if 'Γυμνάσιο' in text: return 'CCV:00057'\n",
    "# if 'Λύκειο' in text: return 'CCV:00061'\n",
    "# if 'Νοσοκομείο' in text: return 'CCV:00073' ή 'CCV:00089'\n",
    "# if 'ΚΕΠ' in text: return 'CCV:00094' ή ''CCV:00029'\n",
    "# if 'Ληξιαρχείο' in text: return 'CCV:00028'\n",
    "# if 'ΑΤ,' in text: return 'CCV:00080'\n",
    "# if len(text) > 30 return 'CCV:00085' \n",
    "# if 'GR' in text: return 'CCV:00098'\n",
    "# if 'bank' in text or 'Bank' in text: return 'CCV:00097'\n",
    "\n",
    "list( df.CCV.unique() ) + ['CCV:00057', 'CCV:00061', 'CCV:00073', 'CCV:00089', 'CCV:00094', 'CCV:00029', \n",
    "'CCV:00028', 'CCV:00080', 'CCV:00085', 'CCV:00098', 'CCV:00097']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If an instance is contained in two or more CCVs, then we randomly choose one of them\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "select_indices = df.drop('CCV', axis=1).drop_duplicates().index\n",
    "\n",
    "df = df.iloc[select_indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input/output ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 865/376500 [00:20<47:45, 131.10it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "X = np.array( [nlp(x).vector for x in tqdm(df['Value'].values)] )\n",
    "\n",
    "np.savez('Data/data.npz', X=X, entity_type=df['Evidence_type'].to_numpy(), y=df['CCV'].to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ...\n",
    "y = df['CCV'].to_numpy()\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "params = {\n",
    "    'n_estimators'      : 50,\n",
    "    'learning_rate'     : 1e-1,\n",
    "    'max_depth'         : 6,\n",
    "    'reg_alpha'         : 20, #trial.suggest_categorical('reg_alpha', [10, 20, 30]),\n",
    "    'reg_lambda'        : 1.0, #trial.suggest_loguniform('reg_lambda', 0, 1),\n",
    "    'gamma'             : 1, #trial.suggest_loguniform('gamma', 1 , 9),\n",
    "    'min_child_weight'  : 2, #trial.suggest_int('min_child_weight', 2, 4),\n",
    "    'max_leaves'        : 2, #trial.suggest_int('max_leaves', 2, 5),\n",
    "    'eval_metric':'auc'\n",
    "}\n",
    "\n",
    "model = xgboost.XGBClassifier(objective           = 'multi:softmax',  \n",
    "                                n_jobs              = -1,                                   \n",
    "                                validate_parameters = True, \n",
    "                                verbosity           = 1,\n",
    "                                tree_method         = 'hist',\n",
    "                                **params)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "trainY = le.fit_transform(y)\n",
    "\n",
    "weights = [y.shape[0] /np.where(y == i)[0].shape[0] for i in np.unique(y)]\n",
    "\n",
    "model.fit(X, y,\n",
    "        eval_set = [ (X, y) ],\n",
    "        sample_weight = [weights[int(x)] for x in y],\n",
    "        verbose = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# Setup dimensionality reduction model\n",
    "umap_model = umap.UMAP(n_neighbors=5, \n",
    "                       n_components=15, \n",
    "                       metric='euclidean',\n",
    "                       random_state=42)\n",
    "\n",
    "\n",
    "X_d = umap_model.fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
